{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cd8863",
   "metadata": {},
   "source": [
    "### 4.1 Coding LLM architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a2210",
   "metadata": {},
   "source": [
    "We specify the configuration of the small GPT-2 model via the following Python dictio-<br>\n",
    "nary, which we will use in the code examples later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1ad7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d835bbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19dd46",
   "metadata": {},
   "source": [
    "#### 4.1 A placeholder for GPT model architecture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5634c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "                            *[DummyTransformerBlock(cfg)\n",
    "                                for _ in range(cfg[\"n_layers\"])]) # Use a placeholder for transformer block\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) # Use a placeholder layernorm\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False) \n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51a0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196caa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0448,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape: \", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d1901",
   "metadata": {},
   "source": [
    "#### 4.2 Normalizing activations with layer normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c5b6d",
   "metadata": {},
   "source": [
    "Training deep neural networks with many layers can sometimes prove challenging\n",
    "due to problems like vanishing or exploding gradients. These problems lead to unsta-\n",
    "ble training dynamics and make it difficult for the network to effectively adjust its\n",
    "weights, which means the learning process struggles to find a set of parameters\n",
    "(weights) for the neural network that minimizes the loss function. In other words, the\n",
    "network has difficulty learning the underlying patterns in the data to a degree that\n",
    "would allow it to make accurate predictions or decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273eb7c",
   "metadata": {},
   "source": [
    "The main idea behind `layer normalization` is to adjust the activa-<br>\n",
    "tions (outputs) of a neural network layer to have a mean of 0 and a variance of 1, also <br>\n",
    "known as unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89050ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b5b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f922e53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer output:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print('Normalized layer output:\\n', out_norm)\n",
    "print('Mean:\\n', mean)\n",
    "print('Variance:\\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fe76de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print('Mean:\\n', mean)\n",
    "print('Variance:\\n', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67938b1",
   "metadata": {},
   "source": [
    "#### A `layer normalization` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53cf230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d64839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Var: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, keepdim=True, unbiased=False)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Var: \\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5654e9",
   "metadata": {},
   "source": [
    "#### 4.3 Implement `GLEU` activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a114ed",
   "metadata": {},
   "source": [
    "$GLEU(x) = x \\mbox{ } \\Phi(x)$, where $\\Phi(x)$ is the cumulative distribution function <br>\n",
    "of standard gaussian distribution. In practice its common to implement computationally cheaper option.\n",
    "\\begin{equation}\n",
    "GELU(x) \\approx 0.5 x ( 1 + tanh [ \\sqrt{\\frac{2}{\\pi}} (x + 0.044715 x^{3}) ] )\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7a307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.44715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d79a328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2824a14",
   "metadata": {},
   "source": [
    "#### A feed-forward neural network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab2a1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d53ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb8cef",
   "metadata": {},
   "source": [
    "#### 4.4 Adding shortcut (Residual) connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c67c3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        \n",
    "        #implement five layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "                         GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),\n",
    "                         GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), \n",
    "                         GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), \n",
    "                         GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),\n",
    "                         GELU())\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3207eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6498573",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_without_shortcut(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833718f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    \n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c869f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020471324387472123\n",
      "layers.1.0.weight has gradient mean of 0.0001231795467901975\n",
      "layers.2.0.weight has gradient mean of 0.0007344745099544525\n",
      "layers.3.0.weight has gradient mean of 0.0013871212722733617\n",
      "layers.4.0.weight has gradient mean of 0.005026495084166527\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f63a1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.29920274019241333\n",
      "layers.1.0.weight has gradient mean of 0.2749510407447815\n",
      "layers.2.0.weight has gradient mean of 0.45466116070747375\n",
      "layers.3.0.weight has gradient mean of 0.362958699464798\n",
      "layers.4.0.weight has gradient mean of 1.763088583946228\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cadb5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.6983, 1.0865])\n",
      "Attention weights:  tensor([0.1456, 0.2281, 0.2251, 0.1287, 0.1066, 0.1658])\n",
      "Sum:  tensor(1.)\n",
      "Attention weights:  tensor([0.1387, 0.2381, 0.2335, 0.1241, 0.1073, 0.1583])\n",
      "Sum:  tensor(1.0000)\n",
      "tensor([0.4416, 0.6508, 0.5687])\n",
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4561, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.6983, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7069, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3416, 0.6565],\n",
      "        [0.4561, 0.6983, 0.7069, 0.3416, 0.6605, 0.2855],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2855, 0.9450]])\n",
      "Attn scores:\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4561, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.6983, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7069, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3416, 0.6565],\n",
      "        [0.4561, 0.6983, 0.7069, 0.3416, 0.6605, 0.2855],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2855, 0.9450]]) \n",
      "Attn weights:\n",
      "  tensor([[0.2099, 0.2006, 0.1982, 0.1243, 0.1219, 0.1452],\n",
      "        [0.1387, 0.2381, 0.2335, 0.1241, 0.1073, 0.1583],\n",
      "        [0.1391, 0.2371, 0.2328, 0.1243, 0.1100, 0.1566],\n",
      "        [0.1436, 0.2075, 0.2047, 0.1463, 0.1257, 0.1722],\n",
      "        [0.1534, 0.1954, 0.1971, 0.1368, 0.1881, 0.1293],\n",
      "        [0.1386, 0.2185, 0.2129, 0.1422, 0.0981, 0.1897]])\n",
      "tensor([[0.2099, 0.2006, 0.1982, 0.1243, 0.1219, 0.1452],\n",
      "        [0.1387, 0.2381, 0.2335, 0.1241, 0.1073, 0.1583],\n",
      "        [0.1391, 0.2371, 0.2328, 0.1243, 0.1100, 0.1566],\n",
      "        [0.1436, 0.2075, 0.2047, 0.1463, 0.1257, 0.1722],\n",
      "        [0.1534, 0.1954, 0.1971, 0.1368, 0.1881, 0.1293],\n",
      "        [0.1386, 0.2185, 0.2129, 0.1422, 0.0981, 0.1897]])\n",
      "tensor([[0.4420, 0.5919, 0.5791],\n",
      "        [0.4416, 0.6508, 0.5687],\n",
      "        [0.4428, 0.6489, 0.5675],\n",
      "        [0.4301, 0.6288, 0.5514],\n",
      "        [0.4671, 0.5884, 0.5266],\n",
      "        [0.4174, 0.6497, 0.5649]])\n",
      "previous context vector:  tensor([0.4416, 0.6508, 0.5687])\n",
      "tensor([0.4306, 1.4551])\n",
      "keys:  tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1809, 0.3220],\n",
      "        [0.3275, 0.9642]])\n",
      "values:  tensor([[0.1855, 0.8812],\n",
      "        [0.3951, 1.0037],\n",
      "        [0.3879, 0.9831],\n",
      "        [0.2393, 0.5493],\n",
      "        [0.1460, 0.3306],\n",
      "        [0.3221, 0.7863]])\n",
      "tensor(1.8524)\n",
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5464, 1.5440])\n",
      "tensor([0.1501, 0.2265, 0.2200, 0.1312, 0.0900, 0.1822])\n",
      "tensor([0.3059, 0.8210])\n",
      "tensor([[0.2993, 0.8052],\n",
      "        [0.3059, 0.8210],\n",
      "        [0.3056, 0.8203],\n",
      "        [0.2945, 0.7936],\n",
      "        [0.2922, 0.7885],\n",
      "        [0.2988, 0.8039]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.5332, -0.1044],\n",
      "        [-0.5318, -0.1073],\n",
      "        [-0.5318, -0.1072],\n",
      "        [-0.5291, -0.1069],\n",
      "        [-0.5305, -0.1058],\n",
      "        [-0.5293, -0.1073]], grad_fn=<MmBackward0>)\n",
      "W_query Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]], requires_grad=True)\n",
      "W_key Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]], requires_grad=True)\n",
      "W_value Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]], requires_grad=True)\n",
      "W_query.weight Parameter containing:\n",
      "tensor([[0.2961, 0.2517, 0.0740],\n",
      "        [0.5166, 0.6886, 0.8665]], requires_grad=True)\n",
      "W_key.weight Parameter containing:\n",
      "tensor([[0.1366, 0.1841, 0.3153],\n",
      "        [0.1025, 0.7264, 0.6871]], requires_grad=True)\n",
      "W_value.weight Parameter containing:\n",
      "tensor([[0.0756, 0.3164, 0.1186],\n",
      "        [0.1966, 0.4017, 0.8274]], requires_grad=True)\n",
      "tensor([[0.1552, 0.2106, 0.2061, 0.1414, 0.1068, 0.1800],\n",
      "        [0.1501, 0.2265, 0.2200, 0.1312, 0.0900, 0.1822],\n",
      "        [0.1505, 0.2258, 0.2194, 0.1316, 0.0908, 0.1820],\n",
      "        [0.1592, 0.1995, 0.1963, 0.1478, 0.1202, 0.1770],\n",
      "        [0.1612, 0.1947, 0.1921, 0.1503, 0.1265, 0.1752],\n",
      "        [0.1558, 0.2093, 0.2050, 0.1420, 0.1084, 0.1795]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0.1552, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1501, 0.2265, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1505, 0.2258, 0.2194, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1592, 0.1995, 0.1963, 0.1478, 0.0000, 0.0000],\n",
      "        [0.1612, 0.1947, 0.1921, 0.1503, 0.1265, 0.0000],\n",
      "        [0.1558, 0.2093, 0.2050, 0.1420, 0.1084, 0.1795]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3986, 0.6014, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2526, 0.3791, 0.3683, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2265, 0.2839, 0.2794, 0.2103, 0.0000, 0.0000],\n",
      "        [0.1954, 0.2361, 0.2329, 0.1823, 0.1533, 0.0000],\n",
      "        [0.1558, 0.2093, 0.2050, 0.1420, 0.1084, 0.1795]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[0.9231,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [1.2705, 1.8524,   -inf,   -inf,   -inf,   -inf],\n",
      "        [1.2544, 1.8284, 1.7877,   -inf,   -inf,   -inf],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925,   -inf,   -inf],\n",
      "        [0.6052, 0.8730, 0.8538, 0.5069, 0.2627,   -inf],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3856, 1.0996]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3986, 0.6014, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2526, 0.3791, 0.3683, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2265, 0.2839, 0.2794, 0.2103, 0.0000, 0.0000],\n",
      "        [0.1954, 0.2361, 0.2329, 0.1823, 0.1533, 0.0000],\n",
      "        [0.1558, 0.2093, 0.2050, 0.1420, 0.1084, 0.1795]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n",
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.2029, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7366, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4529, 0.5677, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3908, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4186, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 6, 3])\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n",
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5519, -0.0972,  0.5315,  0.3418],\n",
      "         [-0.5293, -0.1073,  0.5072,  0.3485]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5519, -0.0972,  0.5315,  0.3418],\n",
      "         [-0.5293, -0.1073,  0.5072,  0.3485]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape:  torch.Size([2, 6, 4])\n",
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n",
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.Chapter_3 import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bdf8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Pre-layerNorm is better than post-layernorm\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe22e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([2, 4, 768])\n",
      "Output shape:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "print(\"Output shape: \", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581be068",
   "metadata": {},
   "source": [
    "### The GPT model architecture implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "801826c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7607edc",
   "metadata": {},
   "source": [
    "Let’s now initialize the 124-million-parameter GPT model using the `GPT_CONFIG_\n",
    "124M` dictionary we pass into the `cfg` parameter and feed it with the batch text input\n",
    "we previously created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeb840b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e570c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape:  torch.Size([2, 4, 50257])\n",
      "torch.Size([4, 50257])\n"
     ]
    }
   ],
   "source": [
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape: \", out.shape)\n",
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2ba999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7f609dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape:  torch.Size([50257, 768])\n",
      "Output layer shape:  torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape: \", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape: \", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a663ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel()\n",
    "                      for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable parameters \"\n",
    "      f\"considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a6a7263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85026816"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.trf_blocks.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a836b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855766a1",
   "metadata": {},
   "source": [
    "## 4.7 Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec73e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "            \n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38137e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print('encoded:', encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "001a8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45d6d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "print('encoded_tensor.shape:', encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4e20314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(model, encoded_tensor, 6, GPT_CONFIG_124M[\"context_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b190e0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 29739,   554]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "73a9e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = model.tok_emb(encoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f36fa404",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.out_head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "240385ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' repairing'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(k.squeeze(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61f67421",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(encoded_tensor[:, -GPT_CONFIG_124M[\"context_length\"]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f9f216f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e2f5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3e42ac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7df7829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.argmax(probs, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d2250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73213062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  tensor([[[ 0.1570,  0.3790, -0.1052,  ...,  1.2618,  0.3342,  0.7445],\n",
      "         [ 0.0330,  0.0517,  0.2529,  ...,  0.4698,  0.1187,  0.9938],\n",
      "         [ 0.5532,  0.5810, -0.0384,  ...,  1.1717,  0.3839,  0.7470],\n",
      "         [ 0.1784,  0.7126,  0.7358,  ...,  0.3408,  0.5483,  0.9467]],\n",
      "\n",
      "        [[ 0.1873,  1.1682,  0.5817,  ...,  0.1806,  0.0093, -0.5668],\n",
      "         [-0.3046,  0.6550,  0.1793,  ...,  0.3088,  0.4487, -0.0436],\n",
      "         [ 0.9321,  0.4172,  0.2954,  ...,  0.3836,  0.7352, -0.1030],\n",
      "         [ 0.5907,  0.5709,  0.3323,  ...,  1.3798,  1.2681,  0.3915]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "output length:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"output: \", output)\n",
    "print(\"output length: \", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718f320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
